\chapter{Estado del Arte}\label{chapter: sota}

Con el incremento constante de la cantidad de información generada en todo el mundo, la recuperación de información se ha convertido en un aspecto de creciente relevancia tanto en el ámbito industrial como en el académico. En consecuencia, la reducción del tiempo transcurrido entre el momento en que un usuario desea acceder a la información y el momento en que efectivamente puede hacerlo ha sido objeto de un número creciente de investigaciones científicas en los últimos años \cite{text2sql1} \cite{text2cypher1}. Este capítulo se dedica a la evaluación de diversas estructuras de interfaces entre el ser humano y bases de conocimiento, las cuales tienen como objetivo abordar esta problemática.

Las Interfaces de Lenguaje Natural a Bases de Datos (NLIDB, por sus siglas en inglés) \cite{nlidb} representan un campo de investigación dinámico centrado en facilitar las interacciones entre humanos y computadoras con bases de datos relacionales utilizando consultas en lenguaje natural. A lo largo de las últimas décadas, el desarrollo de NLIDB ha pasado por varias fases transformadoras, impulsadas por avances tecnológicos y metodológicos, así como por una creciente demanda de una mejor accesibilidad a las bases de datos.

Las etapas iniciales del desarrollo de NLIDB se caracterizaron por sistemas específicos de dominio. Estos sistemas fueron diseñados para trabajar dentro de áreas de conocimiento bien definidas, donde se utilizaba el procesamiento de lenguaje natural controlado para garantizar la comprensión de las consultas y la interacción con la base de datos. Por ejemplo, algunos trabajos pioneros como el de Androutsopoulos et al. \cite{androutsopoulos1995natural} demostraron NLIDBs que se adaptaban a dominios específicos, lo que los hacía altamente efectivos pero limitados en alcance. Del mismo modo, en años posteriores Popescu et al. \cite{popescuetal2003} continuaron la exploración del uso de interfaces de lenguaje natural controlado dentro de dominios de conocimiento particulares.

Otro enfoque durante esta fase implicó NLIDBs basados en reglas. Algunos sistemas propuestos al respecto, como el de Stratica et al. \cite{straticaetal2005}, dependían de reglas predefinidas para traducir consultas en lenguaje natural en declaraciones \textit{SQL} para la recuperación de datos en la base de datos. Si bien estos sistemas ofrecían ciertas ventajas, carecían de versatilidad para manejar una amplia gama de consultas de usuarios en diferentes dominios.

A medida que avanzaba la investigación en NLIDB, hubo un cambio hacia la independencia de dominio y la flexibilidad. Los sistemas recientes han buscado reducir la dependencia del conocimiento específico del dominio y las reglas. Algunos investigadores como Zhong et al. \cite{zhongetal2017} y Yu et al. \cite{yuetal2018}) han desarrollado NLIDBs que utilizan técnicas de aprendizaje supervisado, lo que los hace más adaptables a varios dominios y entradas de usuario. Además, un avance significativo se ha producido con la integración de redes neuronales profundas en el desarrollo de NLIDBs, donde autores como Dong y Lapata \cite{dongandlapata2016} han demostrado el potencial del aprendizaje profundo en NLIDB, aprovechando vastos repositorios de texto y código para el entrenamiento. Este enfoque ha mejorado significativamente el rendimiento de NLIDB, permitiendo un procesamiento de consultas más natural y contextual.

Para el caso específico de NLIDB con respecto a BDOGs inicialmente se desarrollaron trabajos enfocados en técnicas similares a las empleadas para \textit{SQL} \cite{adrianbazaga2021} \cite{hainsetal2020}, donde se realizaba un preprocesamiento en la consulta dada, se aprovechaba la información ofrecida por el esquema \cite{dbschema} de la base de datos a consultar y finalmente dicho conocimiento era utilizado por un modelo de aprendizaje profundo entrenado sobre un conjunto de pares de lenguaje natural y lenguaje de consulta formal como por ejemplo \textit{Cypher}.

Recientemente, los trabajos orientados a esta área de estudio han estado enfocados en dos metodologías principales que serán tratadas en las secciones \ref{neurosymbolic_approach} y \ref{llm_approach}:
\begin{enumerate}
	\item Enfoques neurosimbólicos basados en representación intermedia de la consulta dada en lenguaje natural.
	\item Enfoques basados en técnicas de \textit{prompt engineering} mediante LLMs.
\end{enumerate}

\section{Preliminares} \label{prelude}

\subsection{Bases de Datos \textit{Neo4J}} \label{neo4jdbs}
El sistema \textit{Neo4J} emerge como una plataforma de base de datos de grafos preeminente, distinguiéndose por su capacidad para manejar datos interconectados con una eficiencia y flexibilidad notables \cite{robinsonwebbereifrem2015}. Este sistema gestiona las relaciones entre los datos con una estructura nodal y de aristas, lo que permite una representación más natural de las interconexiones inherentes a muchos conjuntos de datos \cite{millerandrodriguez2013}.

La potencia de \textit{Neo4J} reside en su lenguaje de consulta, \textit{Cypher}, que permite expresar consultas sobre grafos de manera declarativa. \textit{Cypher} es específicamente diseñado para ser intuitivo y potente, proporcionando comandos que facilitan la realización de patrones de búsqueda complejos y análisis de relaciones en una forma compacta y legible \cite{neo4j}.

En términos de rendimiento,  \textit{Neo4J} está diseñado para maximizar la velocidad y eficiencia en la recuperación y manejo de datos relacionales. Utiliza índices basados en árboles B+ y algoritmos de ruta como el de Dijkstra y A* para búsquedas optimizadas en el grafo \cite{neo4j2021dijkstra} \cite{neo4j2021astar}. Además, la integridad de los datos se garantiza mediante propiedades transaccionales ACID \cite{acidtransaction}, que son fundamentales en aplicaciones críticas de negocio \cite{vukoticabedrabboandpartner2014}.

La escalabilidad de  \textit{Neo4J} es una de sus características más destacables, con soporte para configuraciones en clúster que permiten la replicación de datos y la tolerancia a fallos, asegurando la disponibilidad y la escalabilidad horizontal \cite{neo4j}. Esto es esencial para aplicaciones que requieren un rendimiento consistente bajo cargas de trabajo de lectura y escritura intensivas.

La versatilidad de integración de Neo4j también merece ser subrayada. Su compatibilidad con API REST, diversos lenguajes de programación y frameworks de desarrollo facilita su adopción en arquitecturas de software existentes \cite{neo4j}. Esto se complementa con una comunidad activa y recursos extensos para desarrolladores, lo que promueve una continua innovación y adopción en la industria \cite{neo4jusecases}.

\begin{figure}[H]\label{neo4jdb}
	\centering
	\includegraphics[width = 0.9\textwidth]{./Graphics/neo4j}
	\caption{Ejemplo de representación de información en una base de datos \textit{Neo4J}. Nótese la estructura de nodos para representar información de entidades y de aristas que corresponden a relaciones entre estas.}
\end{figure} 

\subsection{Lenguaje \textit{Cypher}} \label{cypher_language}

El lenguaje de consulta utilizado en \textit{Neo4J} es \textit{Cypher}, un lenguaje declarativo centrado en el "qué" en lugar del "cómo" cuando se trata de recuperar datos. Esta naturaleza permite a los usuarios especificar patrones en los grafos sin requerir que ellos describan los algoritmos o pasos lógicos para encontrar esos patrones \cite{cypher}. A continuación se mencionan algunos aspectos relevantes de este lenguaje de consulta formal y cómo facilitan la interacción con bases de datos de grafos como \textit{Neo4J}.

\begin{enumerate}

\item \textbf{Patrones de coincidencia (Pattern Matching)}:
Cypher utiliza una sintaxis que se asemeja a los diagramas de entidad-relación ASCII para patrones de coincidencia, lo que facilita la representación visual de la estructura del grafo en el propio código \cite{millerandrodriguez2013}. Su sintaxis intuitiva hace que la comprensión y escritura de consultas sea más accesible, especialmente para usuarios nuevos en el manejo de bases de datos de grafos. Por ejemplo, para encontrar a un usuario y sus amigos en \textit{Neo4J}, podríamos escribir una consulta como:

\begin{figure}[h]
\begin{center}
\begin{lstlisting}[language=cypher]
MATCH (user:Person)-[:FRIEND]->(friend) RETURN user, friend
\end{lstlisting}
\caption{Ejemplo de código \textit{Cypher}.}
\end{center}
\end{figure}

\item \textbf{Filtrado y condiciones}: \textit{Cypher} permite incorporar condiciones dentro de los patrones de coincidencia o en cláusulas \texttt{WHERE} para filtrar resultados. Esto se asemeja al uso de \texttt{WHERE} en \textit{SQL} pero está optimizado para trabajar con las conexiones entre nodos.

\item \textbf{Agregación de datos}: \textit{Cypher} proporciona funciones de agregación, como \texttt{COUNT}, \texttt{SUM}, \texttt{AVG}, \texttt{MAX} y texttt{MIN}, que permiten realizar cálculos sobre grupos de datos. Estas funciones son esenciales para resumir información sobre los datos conectados.

\item \textbf{Modificación de grafos}: Además de recuperar datos, \textit{Cypher} puede ser utilizado para crear, actualizar y eliminar nodos y relaciones. Esto incluye la capacidad de manejar transacciones y asegurar la integridad de los datos.

\item \textbf{Optimización de consultas}: \textit{Cypher} está diseñado para optimizar las consultas de grafos de forma automática. El planificador de consultas de \textit{Neo4J} reorganiza y optimiza las operaciones de consulta para una ejecución eficiente, lo que abstrae una capa de complejidad para los desarrolladores.

\item \textbf{Extensibilidad}: \textit{Cypher} es extensible, lo que significa que se pueden crear funciones definidas por el usuario y procedimientos almacenados que se pueden invocar dentro de las consultas. Esto permite personalizar y ampliar la funcionalidad del lenguaje para satisfacer necesidades específicas.

\item \textbf{Interoperabilidad}: A través de su protocolo \textit{Bolt} y la API REST, \textit{Cypher} puede ser utilizado desde una variedad de lenguajes de programación y entornos, permitiendo que sistemas externos interactúen con \textit{Neo4J}.

\end{enumerate}

\subsection{Grandes modelos de Lenguaje y Generación de Lenguajes de Consulta Formales} \label{llms_prelude}

Los Grandes Modelos de Lenguaje (LLMs) son una clase de modelos de procesamiento de lenguaje natural que han revolucionado la forma en que las computadoras comprenden y generan texto. Estos modelos se destacan por su capacidad para generar texto coherente y contextualmente relevante en función del contexto proporcionado. Esta habilidad es esencial cuando se trata de generar código de consulta en lenguajes formales como \textit{Cypher} o text{SQL} \cite{llmsoverview}.

Una de las ventajas clave de los LLMs es su capacidad para traducir preguntas en lenguaje natural en consultas en lenguaje formal de manera automática. Esto significa que pueden tomar preguntas como \textquotedblleft ¿Cuál es la población de Nueva York? \textquotedblright y convertirlas en consultas \textit{SQL} precisas, como \texttt{SELECT population FROM cities WHERE name = 'Nueva York'}. Esta traducción automática simplifica significativamente la interacción entre humanos y sistemas de bases de datos, ya que elimina la necesidad de que los usuarios aprendan el lenguaje formal \cite{mehrietal2019}.

Otra característica destacada es la versatilidad de los LLMs en términos de lenguajes de consulta. No están limitados a un lenguaje específico; pueden generar consultas en varios lenguajes formales. Esto significa que pueden interactuar con diferentes sistemas de bases de datos que utilizan diferentes lenguajes de consulta, desde \textit{SQL} hasta \textit{Cypher} y \textit{SPARQL}, entre otros \cite{llmsoverview}.

Los LLMs también demuestran un fuerte entendimiento de contextos complejos en sus respuestas. Pueden manejar preguntas que involucran múltiples condiciones, cláusulas \texttt{JOIN}, filtros y agregaciones en las consultas, lo que los hace aptos para abordar consultas complejas en bases de datos \cite{mehrietal2019}.

Por último, estos modelos tienen la capacidad de inferir relaciones y estructuras de datos a partir del contexto proporcionado. Esto les permite generar consultas que exploran conexiones y patrones en los datos de una base de datos de manera inteligente, lo que es especialmente valioso en aplicaciones de análisis de datos y minería de información \cite{llmsoverview}.

\section{Extracción de conocimiento mediante enfoques neurosimbólicos basados en representación intermedia (IR, por sus siglas en inglés) de la consulta dada en lenguaje natural} \label{neurosymbolic_approach}

Con respecto a la recuperación de información de una base de conocimiento con este enfoque, mediante consultas hechas en lenguaje natural se han hecho varias investigaciones científicas que se pueden agrupar bajo el patrón de la Figura \ref{neurosym_approach}.

\begin{figure*}[!h]\label{neurosym_approach}
	\centering
	\includegraphics[width = 0.9\textwidth]{./Graphics/neurosym_approach}
	\caption{Secuencia de flujo representativa del Estado del Arte de traducción de
Lenguaje Natural a Lenguaje Formal utilizando el enfoque neurosimbólico basado en (IR) \cite{omarthesis2022}.}
\end{figure*}

\subsection{Conjuntos de entranamiento y evaluación} \label{neurosymbolic_approach_bechmarks}

En cuanto a los datos para el entrenamiento existen dos opciones. Básicamente se puede buscar un conjunto de datos de referencia(\textit{Benchmark}) en los que entrenar y probar el sistema, o se crea uno. La mayoría de las investigaciones existentes elijen la primera opción. Algunos de los \textit{Benchmarks} más populares son:

\begin{itemize}
	\item \textbf{WikiSQL}: WikiSQL \cite{zhongetal2017} es el banco de datos más grande y más utilizado, contiene $26531$ tablas y $80654$ pares de consultas en lenguaje natural y lenguaje \textit{SQL}. Las tablas se extraen de tablas \textit{HTML} de Wikipedia. Luego, cada consulta en \textit{SQL} se genera automáticamente para una determinada tabla bajo la restricción de que la consulta produce un conjunto de resultados no vacío.

	\item \textbf{Spider}: Este \textit{Benchmark} \cite{spiderdataset} es un punto de referencia multidominio a gran escala con 200 bases de datos de 138 dominios diferentes y 10.181 pares de consultas.

	\item \textbf{MetaQA}: El conjunto de datos \textit{MetaQA} \cite{metaqa} contiene más de $400000$ pares de preguntas y respuestas de múltiples pasos obtenidos de la base de conocimiento WikiMovies \cite{milleretal2016}. Mientras que investigaciones previas se han centrado principalmente en la anotación SPARQL \cite{huangetal2021}, nuestra innovación implica reconfigurar METAQA en \textit{Cypher}, estableciéndolo como un valioso punto de referencia para el aprendizaje de pocos ejemplos.

\end{itemize}

En el caso alternativo, se suelen usar las propias bases de conocimiento objeto de estudio para crear un conjunto de entrenamiento. Una de las técnicas empleadas para esto es Random Walk \cite{randomwalk}, en la que se hace un recorrido aleatorio sobre un subconjunto de las entidades y relaciones de la base de conocimiento, y se elaboran consultas artificiales que respondan a dichas entidades y relaciones \cite{adrianbazaga2021}.

\subsection{Preprocesamiento} \label{neurosym_approach_preprocessing}

En general las investigaciones en el área realizan algún tipo de preprocesamiento a la consulta. Algunos realizan parafraseo para llevar la consulta a representaciones canónicas, en su lugar otros realizan un análisis morfológico léxico, con toquenización, lematización, eliminación de stopwords, tagueo de partes de la oración (\textit{POS-taguing}), etc. \cite{Singh2016Algorithm}. También se encuentran las investigaciones que usan en esta etapa traducciones basadas en diccionarios especializados en el dominio, o de propósito general, al igual que ontologías, para "suavizar" vocablos difíciles de entender por el resto del sistema \cite{Sathick2015Natural}. Además se usan técnicas como vectorización de palabras (\textit{word2vector}) \cite{Wenhuchen}, y transformación de la consulta a una representación en grafos \cite{Cai2021SADGA}.

\subsection{Postprocesamiento} \label{neurosym_approach_postprocessing}

En la fase de Post-Procesamiento, se observan diversas enfoques en las investigaciones. La mayoría de los investigadores realizan un análisis semántico que implica la clasificación según tipos de datos, el uso de ontologías y bases de conocimiento externas para realizar mapeos \cite{Singh2016Algorithm}. Algunos optan por convertir la consulta en una representación canónica o en un lenguaje intermedio antes de transpilarla al lenguaje objetivo \cite{Nie2022GraphQ}. También hay quienes la codifican directamente en forma de grafo \cite{adrianbazaga2021}, y algunos la convierten en embeddings \cite{Cai2021SADGA}.

\subsection{Consulta} \label{neurosym_approach_query}

En la fase de construcción de la consulta, existen tres enfoques principales. El primero es un enfoque manual que implica la búsqueda y formateo de palabras clave como \textit{"where"} y \textit{"select"}, además del mapeo de atributos a tablas \cite{Wenhuchen}. Otra vía se centra en el uso de modelos, incluyendo decodificadores y en algunos casos redes neuronales convolucionales \cite{Wu2021FromPT}. También se emplea la construcción de la consulta formal mediante un compilador, especialmente cuando se ha utilizado un lenguaje intermedio entre el lenguaje natural y el formal de consulta\cite{Nie2022GraphQ}.

\section{Extracción de conocimiento mediante enfoques basados en técnicas de \textit{prompt engineering} mediante LLMs} \label{llm_approach}

Con la creciente atención dada a los modelos de lenguaje a gran escala, estos se han convertido en un componente esencial en el procesamiento del lenguaje natural. A diferencia de modelos como BERT \cite{bert} y T5 \cite{t5}, que requieren un proceso de entrenamiento con una pequeña cantidad de datos, modelos como GPT-3 \cite{gpt3} requieren un diseño de un texto de entrada para generar resultados deseados. El reciente modelo de \textit{ChatGPT} \cite{chatgpt}, que emplea Aprendizaje por Reforzamiento para la Retroalimentación Humana (RLHF) \cite{Pangeanic2023Aprendizaje}, simplifica el diseño de textos de entrada de calidad, lo que permite una mejor utilización de la capacidad de ZSL de modelos preentrenados a gran escala de manera conversacional. Debido a la sólida capacidad de dichos en la generación de código \cite{llmsoverview} y al hecho de que los modelos de generación de código suelen requerir una gran cantidad de datos anotados para producir buenos resultados \cite{llmsoverview}, un modelo de generación de código de ZSL se considera fundamental.

Para la tarea específica de generar código de un lenguaje de consulta formal como \textit{SQL} y \textit{Cypher} se han utilizado distintos enfoques basados en varias de las principales técnicas de \textit{prompt engineering}.

\subsection{Zero-Shot Learning} \label{llm_approach_zsl}
	Esta técnica se enfoca en la capacidad de un modelo para comprender y generar código en un lenguaje de consulta sin requerir ejemplos específicos de entrenamiento en ese lenguaje en particular. En otras palabras, el modelo puede realizar esta tarea "desde cero", sin conocimiento previo del lenguaje. Algunos estudio interesantes se han realizado principalmente en la tarea de traducir lenguaje natural a lenguaje \textit{SQL} \cite{text2sqlzsl1} \cite{text2sqlzsl2}, los cuales permiten inferir la calidad mínima que estos modelos pueden alcanzar en la realización de dicha tarea \cite{llmsoverview}.

\begin{figure}[H]\label{zslpromtpsql}
	\centering
	\includegraphics[width = 0.9\textwidth]{./Graphics/zslpromptsql}
	\caption{Ejemplo del flujo de trabajo de experimentos basados en ZSL para la traducción de lenguaje natural a código en \textit{SQL}.}
\end{figure} 

\subsection{Few-Shot Learning} \label{llm_approach_fsl}
	En contraste, el enfoque de Few-Shot Learning (FSL) \cite{fewshotlearning} se basa en la idea de que el modelo tiene acceso a un pequeño número de ejemplos (pocos ejemplos) en el lenguaje de consulta deseado para mejorar su capacidad de generar código en ese lenguaje. Esto puede ser especialmente útil cuando se necesita una adaptación rápida a un nuevo lenguaje o contexto. Tal y como muestran algunos resultados experimentales, este enfoque puede tener resultados superiores a varios modelos basados en \textit{fine-tuning} \cite{ftvsllmtext2sql}.

Un ejemplo notable de esta aplicación es el modelo Codex \cite{codex}, que ha demostrado ser un fuerte baseline en el \textit{benchmark} \textit{Spider} \cite{spiderdataset} sin ninguna fase de entrenamiento. Además, se ha observado que proporcionar un pequeño número de ejemplos en el dominio en el texto de entrada permite a Codex superar a los modelos de estado del arte cuyos parámetros han sido ajustados con pocos ejemplos de pocos dominios \cite{codex}.

En cuanto a los conjuntos de datos, existen varios conjuntos de datos de texto a SQL que han sido propuestos para evaluar el rendimiento de los modelos LLM. Algunos de estos conjuntos de datos incluyen CoSQL, TableQA, DuSQL, CHASE, y BIRD-SQL \cite{wikisql} \cite{CoSQL} \cite{TableQA} \cite{DuSQL} \cite{CHASE} \cite{BIRD-SQL}.

\begin{figure}[H]\label{fslpromtpsql}
	\centering
	\includegraphics[width = 1\textwidth]{./Graphics/fslpromptsql}
	\caption{Ejemplo del flujo de trabajo de experimentos basados en FSL para la traducción de lenguaje natural a código en \textit{SQL}.}
\end{figure}

\subsection{Chain-of-Thought Prompting} \label{llm_approach_cot}

El enfoque de la cadena de pensamiento (\textit{Chain of Thought, CoT}) \cite{llmsoverview} en la conversión de texto a \textit{SQL} ha demostrado ser una estrategia prometedora para mejorar la capacidad de los modelos de lenguaje de gran tamaño (LLMs) para realizar razonamientos complejos. Este enfoque se ha utilizado en varias investigaciones recientes para mejorar la capacidad de los LLMs para realizar tareas de razonamiento complejo, como la conversión de texto a SQL \cite{cotllmssql1}.

Un estudio propuso un nuevo paradigma para la generación de consultas \textit{SQL} a partir de texto, llamado \textit{Divide-and-Prompt}, que divide la tarea en subtareas y luego aborda cada subtarea a través de la cadena de pensamiento. Se presentaron tres métodos basados en la indicación para mejorar la capacidad de los LLMs para generar consultas \textit{SQL} a partir de texto. Los experimentos mostraron que estas indicaciones guían a los LLMs para generar consultas \textit{SQL} a partir de texto con mayor precisión de ejecución \cite{cotllmssql2}.

\begin{figure}[H]\label{fslpromtpsql}
	\centering
	\includegraphics[width = 0.8\textwidth]{./Graphics/cotpromptsql}
	\caption{Ejemplo del flujo de trabajo de experimentos basados en CoT para la traducción de lenguaje natural a código en \textit{SQL}.}
\end{figure}

\subsection{\textit{Fine-Tuning}} \label{llm_approach_finetunig}

El entrenamiento (\textit{fine-tuning}) de un modelo es un proceso que se utiliza para mejorar el rendimiento de un modelo de aprendizaje automático en una tarea específica. En el contexto de la conversión de texto a \textit{SQL}, el este ajuste puede ser utilizado para mejorar la precisión y la eficacia de los modelos de lenguaje de gran tamaño (LLMs) en la generación de consultas \textit{SQL} a partir de texto. Se han realizado estudios  utilizando \textit{fine-tuning} para los modelos LLMs utilizando un conjunto de datos de texto a \textit{SQL}, donde el método principal consistía en entrenar el modelo en el conjunto de datos de entrenamiento y luego ajustar el modelo en un conjunto de datos que contenía consultas \textit{SQL} generadas por humanos. Este método demostró ser efectivo para mejorar la precisión de los modelos LLMs en la generación de consultas \textit{SQL} a partir de texto \cite{finetuningtext2sql}.

Este enfoque constituye una poderosa herramienta  en la conversión de lenguaje natural a \textit{SQL}. Sin embargo, no es una solución mágica, ya que pocas organizaciones tienen conjuntos de datos de entrenamiento para la tarea de traducir lenguaje natural a \textit{SQL} disponibles de manera inmediata. Algunos expertos consideran que las mejores arquitecturas se podrían lograr combinando modelos ajustados con agentes RAG (\textit{Retrieval Augmented Generation}) \cite{raginfo}.

\section{Consideraciones generales} \label{approaches_conclusions}

A pesar del uso comprobado de dichos enfoques, todavía existe una escasez de estudios orientados a la traducción de lenguaje natural a código de consulta a BDOG como por ejemplo \textit{Cypher} \cite{gpt4graphpaper2023}, por lo tanto, es visible la necesidad de elaborar experimentos enfocados en dicha tarea, tomando como bases las ideas anteriormente expuestas. Debido a esto, resulta imprescindible desarrollar las primeras experimentaciones de la tarea en cuestión utilizando el enfoque ZSL, el cual en promedio permite obtener una cota inferior de qué tan efectivos pueden ser los LLMs con respecto a una tarea específica \cite{llmsoverview}.


%\newpage