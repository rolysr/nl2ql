%===================================================================================
% Chapter: Introduction
%===================================================================================
\addcontentsline{toc}{chapter}{Introducción}
\chapter*{Introducción}
%===================================================================================

\qquad 

En la época actual, asistimos a un constante aumento en la producción de información en diversos formatos: visual, auditivo y textual, que abarca todos los ámbitos de la sociedad \cite{datagenworld}. De manera particular, resulta sumamente intrigante la información generada a través del ingenio creativo y la investigación humana. Estos tipos de datos se almacenan debido a su relevancia y a la necesidad de acceder a ellos en el futuro, pudiendo optar por una organización estructurada o no. Sorprendentemente, solo alrededor del 20\% de la información a nivel mundial se encuentra estructurada \cite{structdata}.

Las bases de conocimiento constituyen un tipo particular de bases de datos diseñadas para la administración del saber. Estas bases brindan los medios para recolectar, organizar y recuperar digitalmente un conjunto de conocimientos, ideas, conceptos o datos \cite{orgkb}. La ventaja fundamental de mantener la información de manera estructurada radica en su facilidad para ser consultada, ampliada y modificada. Debido a su utilidad y prevalencia, la recuperación de información a través de consultas en bases de conocimiento se ha convertido en una tarea esencial.

Es primordial que la información almacenada en bases de conocimiento adopte un formato adecuado para permitir búsquedas ágiles y precisas. Entre los formatos más comunes se encuentran los modelos de Entidad-Relación y el modelo Relacional. A pesar de ser enfoques más antiguos, el modelo Relacional (BDR) sigue siendo el más ampliamente utilizado en la actualidad \cite{datamodel}. No obstante, en ocasiones, las características específicas del problema demandan un formato más expresivo, y es en este punto donde las bases de datos orientadas a grafos (BDOG) \cite{graphdbs} entran en juego.

Las BDOG han ganado progresivamente popularidad como una manera efectiva de almacenar información en los últimos años. Estas bases tienen la capacidad de modelar una diversidad de situaciones del mundo real al tiempo que mantienen un alto nivel de simplicidad y legibilidad para los seres humanos. Las BDOG presentan numerosas ventajas en comparación con las bases de datos relacionales \cite{graphdbs}. Esto incluye un mejor rendimiento, permitiendo el manejo más rápido y eficaz de grandes volúmenes de datos relacionados; flexibilidad, ya que la teoría de grafos en la que se basan las BDOG permite abordar diversos problemas y encontrar soluciones óptimas; y escalabilidad, ya que las bases de datos orientadas a grafos permiten una escalabilidad eficaz al facilitar la incorporación de nuevos nodos y relaciones entre ellos. Ejemplo de un sistema de gestión de BDOG es \textit{Neo4J} \cite{neo4j}, a través del cual es posible construir instancias de este tipo de base de datos e interactuar con las mismas a través del lenguaje de programación \textit{Cypher} \cite{cypher}, el cual posee una sintaxis declarativa similar a \textit{SQL} \cite{sqllang}.

Por otro lado, el avance en la comprensión del lenguaje natural se ha visto potenciado con el surgimiento de los grandes modelos de lenguajes (LLMs) \cite{llmsoverview} como GPT-4 \cite{gpt4} o LLaMA-2 \cite{llama2}, los cuales presentan una serie de habilidades emergentes como elaboración de resúmenes de textos, generación de código, razonamiento lógico, traducción lingüística entre otras \cite{llmsskills}. Dichas herramientas constituyen modelos de \textit{Machine Learning} entrenados con un gran volumen de datos, lo cual es posible gracias al número de parámetros con los que estos son configurados \cite{llmsoverview}. 

Usualmente, para el uso de los LLMs basta con ofrecerles como dato de entrada un texto \cite{llmsoverview}, el cual describe la tarea que se espera que estos realicen. Además, son muchas las técnicas existentes para elaborar una entrada de calidad, esto con el objetivo de que la respuesta por parte de dicho modelo de lenguage ofrezca resultados alentadores al respecto, lo cual se conoce como \textit{prompt engineering} \cite{promptengineering}. Una técnica bastante común es \textit{Zero-Shot Learning} (ZSL) \cite{zeroshotlearning}, la cual consiste en describirle a un LLM un procedimiento a realizar sin ofrecer de antemano ejemplos de cómo resolverlo, como por ejemplo, en tareas relacionadas con la generación de código, donde algunos de estos son capaces de generar algoritmos expresados en un lenguaje de programación formal a partir de una sentencia o consulta en lenguaje natural sin recibir como entrada del usuario algunos ejemplos de código, o especificaciones de cómo funciona el lenguaje objetivo a generar \cite{text2code1} \cite{text2code2}. 

Un problema bastante común con el uso de LLMs para la resolución de tareas como responder a consultas de conocimiento sin un contexto previo son las alucinaciones \cite{llmhallucinations}, las cuales provocan que, con cierta probabilidad, estos modelos produzcan como salida afirmaciones erróneas sobre hechos, personas o alguna referencia en el mundo real, lo cual resulta un inconveniente para situaciones donde se realicen consultas en lenguaje natural sobre un dominio reducido, como el referente a una base de conocimiento sobre un tema específico. Por lo tanto, no es suficiente el uso de solamente un LLM para responder a dichas preguntas, sino que también sería necesario que estos cuenten de antemano con una información referente al dominio específico sobre el cual se desea consultar.

En lo que respecta a la comprensión del lenguaje natural y su uso en consultas a bases de conocimiento, existen diversas vías llevadas a cabo y con resultados diversos, donde se hacen análisis sintácticos y semánticos sobre la consulta, muchas veces asistidos por diccionarios o mapas sobre la base de conocimiento en cuestión. Se usan modelos de paráfrasis como técnica de aumento de datos y finalmente \textit{Transformers} o incluso LLMs para llevar de la consulta ya curada al lenguaje de consulta formal o a un lenguaje intermedio capaz de expresar a esta a alto nivel, para finalmente ser ejecutada sobre un sistema de gestión de información \cite{text2sql1} \cite{text2cypher1}.

Por los elementos anteriormente expuestos, resulta interesante la investigación sobre la tarea extraer conocimiento procedente una base de conocimiento a partir de una sentencia en lenguaje natural mediante el uso de LLMs, especialmente el diseño e implementación un experimento capaz de demostrar las capacidades reales de estos para dicho acometido, lo cual designará la importancia de continuar el estudio de dichas herramientas con el objetivo de mejorar los sistemas de extracción de información en BDOG. Resulta importante mencionar que dicho procedimiento requerirá del uso del LLM como un traductor de una consulta producida por un usuario humano a una consulta en un lenguaje formal de consulta que sea equivalente y que permita darle respuesta sobre un sistema de conocimiento predefinido.

\subsection*{Problemática}
Para extraer información procedente de una base de conocimiento basada en una BDOG generalmente, es necesario el uso de un lenguaje de consulta formal que pueda ser ejecutado sobre un sistema de gestión de esta. El enfoque más común para generar dicha consulta formal a partir de una consulta en lenguaje natural humano se basa en utilizar un modelo de aprendizaje automático entrenado para dicho proceso. Sucede que para esta tarea en cuestión, es necesario elaborar ejemplos entrenantes de calidad y luego, ejecutar un proceso de entrenamiento, lo cual representa un importante gasto computacional que puede ser omitido con el uso de modelos ya entrenados para disímiles tareas y con capacidad de generar respuesta a preguntas para las cuales no fueron directamente preparados. Es por esta razón que se hace necesario el uso de un LLM, ya que estos poseen habilidades como la generación de código sin necesidad de ser reentrenados para ser utilizados efectivamente \cite{llmsoverview}, y con ello, interactuar con una BDOG para extraer conocimiento. Por otro lado, debido al problema que tienen los LLMs con el fenómeno de las alucinaciones, se hace necesario encontrar una vía de darle como entrada un contexto mínimo del sistema a consultar, para generar una expresión en un lenguaje formal que pueda ajustarse correctamente al formato de la base de conocimiento objetivo y obtener respuestas correctas sobre la misma. En ese sentido la interrogante científica que compete a esta investigación es: ¿Qué tan efectivos pueden ser los LLMs para extraer información de bases de conocimientos a partir de una descripción de la estructura de esta y sin necesidad de ser entrenado con datos específicos o poseer en su entrada ejemplos de cómo realizar la tarea a llevar a cabo? Finalmente, para abordar dicha interrogante se tiene como hipótesis que, utilizando enfoques basados en el aprendizaje \textit{Zero-Shot} con un LLM y teniendo como dato el esquema de una base de conocimiento a consultar, es posible obtener mejores resultados que utilizando directamente el LLM con la consulta a realizar por el usuario.

\subsection*{Objetivos}
Dadas las ideas anteriores, los objetivos principales del trabajo consisten en diseñar e implementar una estrategia experimental capaz de verificar la capacidad de los LLMs para la consulta en lenguaje natural a bases de conocimiento estructuradas con independencia del dominio, para lo cual se empleará un enfoque basado en el aprendizaje \textit{Zero-Shot}.

Para lograr los objetivos generales se trazaron los siguientes objetivos específicos:

\begin{enumerate}
	\item Estudiar el estado del arte de los modelos de Aprendizaje Automático capaces de hacer predicciones de tipo texto-a-texto.
	\item Analizar el trabajo de tesis sobre este tema anteriormente desarrollado en la facultad.
	\item Implementar un modelo de Aprendizaje Automático capaz de convertir una consulta en lenguaje natural humano a un lenguaje formal que permita obtener datos a partir de una 		base de conocimiento.
	\item Explorar las capacidades de enfoques \textit{Zero-Shot} para la traducción de lenguaje natural al lenguaje \textit{Cypher} con el fin de desarrollar un modelo capaz de realizar dicha tarea sin necesidad de ser entrenados directamente para la misma.
	\item Desarrollar un sistema de evaluación de resultados permitiendo que el conjunto de datos de prueba sea lo más realista posible y con diversos niveles de complejidad.
\end{enumerate}

\subsection*{Organización de la tesis}

El presente documento está estructurado en 5 capítulos que engloban las etapas cubiertas en la investigación. En el capítulo 1, Estado del Arte, se reseña el estado actual de la teoría, herramientas y técnicas más usadas en los temas tratados. En el capítulo 2, Propuesta de Solución, se propone una sistema que responde a algunas de las limitaciones principales de los modelos desarrollados en el estado del arte. Para ello propone una vía de resolver el problema basada fundamentalmente en el aprendizaje \textit{Zero-Shot}. En el capítulo 3, Detalles de Implementación, se describen por menores en la implementación del modelo propuesto como solución, se esclarecen decisiones de diseño, y se muestran porciones del código referente a los componentes principales desarrollados. En el capítulo 4, Análisis Experimental, se sugiere un marco experimental para analizar los resultados obtenidos durante la investigación y se comprueba experimentalmente una mejora con respecto a modelos utilizando enfoques similares en el estado del arte. Finalmente, se formulan las conclusiones, que recogen los resultados obtenidos en la investigación en función de los objetivos definidos, así como las recomendaciones, donde se proponen siguientes líneas de trabajo a ser exploradas en continuación de la investigación actual. Para finalizar se indican las referencias bibliográficas consultadas, con el fin de complementar la información provista en el trabajo.

