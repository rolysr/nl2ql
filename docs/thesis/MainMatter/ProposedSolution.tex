\chapter{Propuesta de Solución}\label{chapter: proposedsolution}

En el presente capítulo se abordará la metodología seguida para diseñar el experimento propuesto en este trabajo \ref{experiment_defref}. Primeramente, se expondrá un marco teórico que formaliza la definición del problema a tratar, esto con el objetivo de presentar los conocimientos base tenidos en cuenta para los enfoques probados. Luego, se detallan los primeros acercamientos desechados \ref{approaches_considered}, argumentando las deficiencias de estos a la hora de arrojar resultados consistentes para la tarea que se desea desarrollar. Finalmente, se detalla la metodología definitiva a implementar, teniendo en cuenta la experiencia obtenida de las anteriores y mostrando su robustez para el análisis experimental \cite{}.

De forma general, el componente común para cada vía de solución constituye la presencia de un Gran Modelo de Lenguaje, pues representan los modelos más recientes utilizados para la tarea en cuestión; además, ofrecen resultados alentadores para el caso de traducción a lenguaje \textit{SQL} según lo visto en la sección \ref{llm_approach}. Por lo tanto, tiene sentido probar su eficacia para traducir a código en \textit{Cypher}, ya que ambos presentan similitudes como lenguajes formales declarativos para consultar bases de datos. Dicho modelo será analizado como una ``caja negra'' capaz de hacer tareas de traducción de lenguaje natural a una consulta semánticamente equivalente en el lenguaje \textit{Cypher}.

Para cada vía de solución se deberá considerar el despliegue de un sistema de gestión de bases de datos para alguna BDOG, ya que es en este componente donde se almacenará la información a extraer por consultas en un lenguaje orientado a este tipo de almacenamiento. En el caso particular de este trabajo, se considerará el uso de \textit{Neo4J}, con el cual se puede interactuar a partir del lenguaje \textit{Cypher} ya mencionado. Por esto, es importante considerar la implementación de un módulo intermedio para interactuar con una instancia del sistema de gestión \textit{Neo4J}.

El enfoque de \textit{prompt engineering} a utilizar será ZSL, por lo tanto, los textos de entrada que se le darán al modelo para la generación de código \textit{Cypher} no contendrán ejemplos de pares de lenguaje natural con su correspondiente traducción al lenguaje de consulta objetivo. Por lo tanto, se tomarán algunas ideas experimentadas en el estado del arte para \textit{SQL} vistas en la sección \ref{}.

\section{Preliminares} \label{problem_formal_definition}

\subsection{Bases de Datos \textit{Neo4J}} \label{neo4jdbs}

\subsection{Lenguaje \textit{Cypher}} \label{cypher_language}

\subsection{Grandes modelos de Lenguaje} \label{cypher_language}

\subsection{Definición del problema \textit{Text-to-Cypher}} \label{problem_definition}
Dentro del ámbito de las bases de datos y las consultas que las acceden, existe una tarea particularmente compleja: traducir preguntas formuladas en lenguaje natural a un lenguaje de consulta estructurado como \textit{Cypher}. Dada una pregunta $Q$, formulada en lenguaje cotidiano, y un esquema de base de datos $S$, el cual se compone a partir del tuplo ${N, A, R}$, donde encontramos múltiples nodos $N$ (que representan instancias de una entidad en la base de datos), atributos $C$ (tanto en nodos como en relaciones) y relaciones entre pares de nodos $R$. La problemática subyacente en el proceso de convertir \textit{Text-to-Cypher} se centra en generar una consulta en lenguaje \textit{Cypher} $Y$ que sea equivalente y responda adecuadamente a la pregunta inicial $Q$ realizada por un usuario humano.

\subsection{LLM para resolver \textit{Text-to-Cypher}} \label{llmfortext2cypher}

Con el auge de la inteligencia artificial y el aprendizaje automático, la tarea de convertir texto en lenguaje natural a código en \textit{Cypher} ha sido recientemente abordada a través de técnicas modernas. En trabajos más recientes, algunos investigadores, \cite{sunetal2023} \cite{liuetal2023}, han abogado por formular esta tarea como un desafío de generación. Utilizando lo que se conoce como "\textit{prompts}" o indicaciones $P$, es posible dirigir y guiar a un gran modelo de lenguaje $M$ en esta labor. Este modelo, una vez entrenado, puede estimar una distribución de probabilidad sobre posibles consultas \textit{Cypher} $Y$. De esta forma, el modelo es capaz de generar, paso a paso y token por token, una consulta apropiada.

La fórmula subyacente para generar la consulta $Y$ se estructura como:
$$P_M(Y|P, S, Q) = \prod_{i=1}^{|Y|}{P_M(Y_i | P, S, Q, Y < i)}$$ \label{llm_query_generation}

Para simplificar, $Y< i$ se refiere al fragmento inicial o prefijo de la consulta \textit{Cypher} que se está construyendo. Mientras que $P_M(Yi|*)$ denota la probabilidad condicional asociada con la generación del i-ésimo token, considerando factores como el prefijo existente $Y<i$, la indicación $P$, el esquema $S$ y la pregunta original $Q$.

Uno de los hallazgos más reveladores en el campo reciente es el concepto de aprendizaje en contexto (ICL, por sus siglas en inglés) \cite{icldefinition}, en el cual, grandes modelos de lenguaje pueden adaptarse y aprender de unos pocos ejemplos presentados en un contexto específico. Esta estrategia, defendida por varios investigadores \cite{sunetal2023} \cite{minetal2022} \cite{pourrezandrafiei2023}, ha mostrado que los LLMs pueden abordar y dominar una amplia variedad de tareas complejas con una cantidad limitada de datos. Sin embargo, hay un equilibrio que mantener: agregar más ejemplos conlleva un aumento en los costos, tanto en términos de mano de obra para preparar esos ejemplos como en términos de costos de procesamiento y tokens al interactuar con APIs avanzadas como la de OpenAI \cite{openaiapi}. En este estudio, el foco recae en trabajar eficientemente con indicaciones al modelo de lenguaje sin requerir ejemplos adicionales.

\section{Diseño de la información entrada al LLM} \label{prompt_design}

\section{Selección del modelo} \label{model_selection}

\section{Enfoques considerados en la evaluación} \label{unused_approaches}

\subsection{Elaboración manual de consultas de prueba} \label{handmade_eval}

\subsection{Generación de consultas de prueba sintéticas} \label{synthetic_eval}

\subsection{\textit{Benchmark} orientado a \textit{Cypher}} \label{bench_eval}

\section{Propuesta de solución diseñada} \label{designed_proposal}

